# Task 1: Language Modeling ðŸ“–  

## ðŸ“Œ **Description**  
This task involves **building a probabilistic language model**, analyzing the impact of **text preprocessing** techniques such as:  
- **Tokenization**  
- **Stop Words Removal**  
- **Case Folding**  
- **Stemming**  

## ðŸŽ¯ **Objective**  
To observe how linguistic operations impact the size of vocabulary and frequency of words.  

---

## ðŸ“Š **Results**  
| Preprocessing Step | Vocabulary Size | Words Distribution | Total Words  |
|-------------------|----------------|-------------|-------------|
| **Raw Data** | 37,408 |![Initial](../images/initial_words_distribution.png)| 494,900 |
| **Stop Words Removed** | 36,191 |![Lowercased](../images/word_distribution_after_lower_case.png)| 263,856 |
| **Case Folding** | 31,134 |![Without Stop Words](../images/word_distribution_after_removing_sw.png)| 263,856 |
| **Stemming** | 24,045 |![Stemmed](../images/word_distribution_after_stemming.png)| 263,856 |

---

## ðŸ“‚ **Files**  
- ðŸ“œ `Language_Modeling.ipynb` â€“ Jupyter Notebook containing the full analysis.  
- ðŸ“„ `stop_words_english.txt` â€“ List of stop words used for filtering.  

---

## ðŸš€ **Usage**
Run the notebook with:  
```bash
jupyter notebook TASK_1_Language_Modeling.ipynb
